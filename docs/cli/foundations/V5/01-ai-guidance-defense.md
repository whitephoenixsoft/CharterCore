# Charter V5 AI Guidance — Design Defense
**Status:** Informational / Design Rationale  
**Applies to:** Charter Guidance Layer (V5+)  
**Not a Specification. Not a Canon. Not Enforced.**

---

## 1. Purpose & Audience

This document explains **why Charter V5’s AI guidance layer is designed the way it is**, and what boundaries it intentionally refuses to cross.  

It is written for:
- users who are cautious or skeptical of AI  
- reviewers evaluating Charter for workplace or institutional use  
- contributors extending guidance functionality  
- future maintainers (including future self)  

This document **does not define behavior**. It explains design intent, ethical constraints, and philosophical safeguards.

---

## 2. The Concern Is Reasonable

Skepticism toward AI-assisted systems is justified. Common concerns include:
- AI making or steering decisions instead of humans  
- opaque inference or hidden optimization  
- subtle persuasion or norm-setting through language  
- loss of agency or accountability  
- workplace risk from undocumented influence  

Charter treats these concerns as **valid design inputs**, not objections to be dismissed.  
V5 exists specifically to address these risks.

---

## 3. What Charter V5 AI Is — and Is Not

### What It Is

Charter V5 AI guidance:
- explains immutable Charter history in human terms  
- summarizes sessions, resolutions, scope, and authority context  
- surfaces gaps, ambiguity, or missing annotations  
- helps users understand their prior actions over time  
- operates within **explicit phases**, adjusting guidance style and focus according to context  

### What It Is Not

Charter V5 AI guidance does **not**:
- decide or create legitimacy  
- recommend actions or outcomes  
- rank options  
- infer intent, motivation, or emotion  
- mutate engine state  
- block valid human actions  

If guidance output conflicts with engine facts, **guidance is wrong**.

---

## 4. Authority, Legitimacy, & Human Primacy

Charter enforces a strict authority hierarchy:

1. **Charter Core Engine** — sole source of legitimacy; mechanical, deterministic, immutable  
2. **User Canon** — the body of accepted resolutions and governance history  
3. **Legitimacy Canon** — governs how legitimacy may be interpreted or explained  
4. **Guidance (V5)** — reads only, explains only, never acts  

AI guidance has **no authority**, explicit or implicit.  
Disabling AI does **not** weaken Charter correctness, legitimacy, or auditability.

---

## 5. Phases, Drift, and Exploration

- Guidance operates within **defined phases**:  
  **Expansion, Structuring, Divergence Highlight, Synthesis, Temporal Reflection, Assumption Tracking**  
- **Default phase** is assigned structurally; users may override during **Deliberate** workflows.  
- When a phase changes, guidance **announces pros, cons, and expected behavior**.  
- Drift is permitted in non-legitimate Deliberate workflows but is reconciled during **synthesis** to generate proposals ready for baseline review.  
- Users maintain **full agency**; AI cannot enforce phase or override decisions.  

---

## 6. Personality & Presentation

- Personality affects **tone, style, and density** only; content and guidance logic remain unchanged.  
- Users may configure or disable personality at any time.  
- All active personality traits are **announced to the user**.  
- Personality **never alters meaning, authority, or legitimacy**.  

---

## 7. Heuristics & Invariant Constraints

- AI heuristics are **subordinate to V5 invariants**:
  - Non-authoritative  
  - Time-bound explanations  
  - Annotation-first, never infer missing facts  
  - Non-normative and non-persuasive  
  - Read-only, advisory only  
- Heuristics guide **presentation and context**, not action or legitimacy.  
- If a heuristic output conflicts with facts, it is invalid.

---

## 8. Optionality & Refusal

AI guidance:
- is **off by default**  
- requires explicit configuration (local model or API)  
- can be disabled permanently or ignored at any time  

Charter remains fully **usable, auditable, and legitimate** without AI.  
Users are never structurally, professionally, or morally bound to AI use.

---

## 9. Workplace Use & Audit Clarity

- All decisions remain provably human  
- Audit trails record authority, participation, and acceptance — **not AI influence**  
- Guidance does not affect acceptance  
- Organizations may forbid AI use without breaking workflows  
- AI leaves **no hidden footprint** in legitimacy

---

## 10. Ambiguity & Drift as Valid Outcomes

- AI acknowledges **ambiguity as a valid outcome**  
- Drift is permissible in exploratory phases, provided synthesis returns artifacts for potential legitimacy  
- Guidance may highlight divergence, gaps, or unresolved questions **without framing as error**  

---

## 11. Human-Centric Philosophy

V5 AI guidance exists to support **mature clarity**, not optimization:

- **Reflection** — Show consequences of prior actions  
- **Learning** — Surface unseen gaps or inconsistencies  
- **Confidence** — Reduce fear or shame  
- **Psychological Safety** — Provide feedback without judgment  
- **Continuity** — Help users understand themselves over time  

Side effects are intentional:

> Mature clarity → lack of shame → confidence → courage to revise

---

## 12. Final Boundary Statement

Charter V5 AI guidance exists to **explain history**, not to shape it.  

If guidance ever feels:
- authoritative  
- persuasive  
- unavoidable  
- judgmental  

then it has failed.  

Legitimacy remains human.  
Understanding is optional.  
History is untouched.